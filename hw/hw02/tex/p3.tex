\begin{problem}
  In this problem we will test the performance of linear conjugate gradient method for minimizing quadratic function $f(x) = \frac{1}{2}x\transpose Ax - b \transpose x$, where $A$ is symmetric and positive definite.

  \begin{itemize}
    \item Program CG Algorithm~5.2 in the textbook.

    \item Apply your program on a symmetric and positive definite matrix $A$ of dimension $10^{3} \times 10^{3}$ with eigenvalues uniformly distributed between~$10$ and~$10^3$. Test the convergence of the algorithm and compare your numerical findings with the theoretical result shown in formula (5.36) in the textbook.

    \item Change the distribution of eigenvalues of $A$ so that some eigenvalues are distributed between 9~and~11, the rest of eigenvalues are distributed between 999 and 1001, i.e.,~two clusters around 10~and~1000 with radius~1. Test the convergence performance on such matrix. Extra points if you can explain your numerical findings using the theoretical convergence results discussed in the lecture.
  \end{itemize}
\end{problem}

The Python implementation of the linear conjugate gradient method as detailed in Algorithm~5.2 is included at the end of this submission.  The specific parameters used are enumerated in Table~\ref{tab:p03:ExperimentParams}.  $\mathcal{U}(a,b)$ represents a uniform random variable drawn from the range $[a,b)$.  Note that for all experiments in this problem, the same random $x_0$ vector was used to ensure consistency of results.

\begin{table}[h]
  \centering
  \caption{Parameters for the linear conjugate gradient experiments of problem~\#3}\label{tab:p03:ExperimentParams}
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Parameter} & \textbf{Value} \\
    \hline\hline
    $n$     & 1,000 \\ \hline
    $b$     & $\text{rand}(n,1)$ \\ \hline
    $x_0$   & $2\cdot\text{rand}(n,1)$ \\ \hline
    Uniform & $\mathcal{U}(10,1000)$ \\ \hline
    Bimodal & 10\% from $\mathcal{U}(9,10)$ and 90\% from $\mathcal{U}(999,1001)$\\ \hline
  \end{tabular}
\end{table}

Figures~\ref{fig:p03:uniformEigenvalues} and~\ref{fig:p03:bimodalEigenvalues} show the performance of the linear conjugate gradient method with $n$~uniform and $n$~bimodal eigenvalues respectively.  For matrix~$A$ with bimodal eigenvalues, it took about 15~steps to fully converge. Similar to the results shown in Figure~5.4 of Nocedal and Wright, matrix~$A$ with uniform eigenvalues takes longer to converge. 

Figures~\ref{fig:p03:uniformWeightedErr} and~\ref{fig:p03:bimodalWeightedErr} show the corresponding $A$-weighted error versus the calculated upper bound for the uniform and bimodal eigenvalues respectively.  These results use Nocedal and Wright Eq.~(5.36) which states that:

\[ \wnorm{x_k - \xopt} \leq 2\left(\frac{\sqrt{\kappa(A)}-1}{\sqrt{\kappa(A)}+1}\right)^{k}\wnorm{x_0 - \xopt} \]

\noindent
where $\kappa(A)=\lambda_n / \lambda_1$. For both sets of eigenvalues (i.e., uniform and bimodal), the condition number ${\kappa(A) \approx \frac{1000}{10} = 100}$.  This means that the upper bound estimate will be approximately the same for both experiments.  Observe that the upper bound tracks well for the uniform eigenvalues.  In contrast, the upper bound is quite loose when the eigenvalues are clustered bimodally.  This is expected given an approximately equivalent upper bound and the large difference in Figures~\ref{fig:p03:uniformEigenvalues} and~\ref{fig:p03:bimodalEigenvalues}.

\newpage
\begin{figure}[p]
  \centering
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \input{pgfplots/p03_uniform_eigen}
    \caption{\scriptsize 1,000 $\lambda$ from the distribution $\mathcal{U}(10,10^{3})$}\label{fig:p03:uniformEigenvalues}
  \end{subfigure}
  ~
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \input{pgfplots/p03_bimodal_eigen}
    \caption{\scriptsize 1,000 $\lambda$ from distributions $\mathcal{U}(9,11)$ and $\mathcal{U}(999,1001)$ }\label{fig:p03:bimodalEigenvalues}
  \end{subfigure}
  \caption{Log of cost function $f$ error for problem~\#3}
\end{figure}

\begin{figure}[p]
  \centering
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \input{pgfplots/p03_uniform_weighted_err}
    \caption{\scriptsize Weighted error for 1,000 uniform eigenvalues}\label{fig:p03:uniformWeightedErr}
  \end{subfigure}
  ~
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \input{pgfplots/p03_bimodal_weighted_err}
    \caption{\scriptsize Weighted error for 1,000 bimodal eigenvalues}\label{fig:p03:bimodalWeightedErr}
  \end{subfigure}
  \caption{$A$-weighted error results for problem~\#3}
\end{figure}
\clearpage
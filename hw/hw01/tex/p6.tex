\begin{problem}
  Consider the problem of minimizing:

  \[ f(x_1,x_2) = (cx_{1} - 2)^4 + x_{2}^{2}(cx_{1}-2)^{2} + (x_{2} + 1)^{2} \textrm{,} \]

  \noindent
  where $c$ is a nonzero parameter.
\end{problem}

\begin{subproblem}
  Compute $\nabla f(x)$ and $\nabla f^{2}(x)$, and find the optimal solution.
\end{subproblem}

\noindent
\begin{aligncustom}
  \nabla f(x) &=  \begin{bmatrix}
                          \frac{\partial f(x)}{\partial x_1} \\
                          \frac{\partial f(x)}{\partial x_2}
                        \end{bmatrix} \\
                    &=  \boxed{
                          \begin{bmatrix}
                            4c (cx_{1} - 2)^{3} + 2cx_{2}^{2}(cx_{1}-2) \\
                            2x_2(cx_1-2)^2 + 2(x_2 + 1)
                          \end{bmatrix}
                        }
\end{aligncustom}

\begin{aligncustom}
  \nabla^{2} f(x) &=  \begin{bmatrix}
                        \frac{\partial^{2} f(x)}{\partial x_1^{2}} & \frac{\partial^{2} f(x)}{\partial x_1 \partial x_2} \\
                        \frac{\partial^{2} f(x)}{\partial x_2 \partial x_1} & \frac{\partial^{2} f(x)}{\partial x_{2}^{2}}
                      \end{bmatrix} \\
                  &=  \boxed{
                        \begin{bmatrix}
                          12c^2 (cx_{1} - 2)^{2} + 2c^2x_{2}^{2} & 4cx_2(cx_1 - 2) \\
                          4cx_2(cx_1 - 2) & 2(cx_1-2)^2 + 2
                        \end{bmatrix}
                      }\textrm{.}
\end{aligncustom}

The gradient,~$\nabla f(x)$, above was set equal to~$\vec{0}$ and the roots were solved for in Maple.  It returned root~$\boxed{\left(\frac{2}{c}, -1\right)\transpose}$.  To verify it is a local minimum, we need to substitute this into the Hessian.  Therefore,

\begin{aligncustom}
    \nabla^{2} f(x^{*}) &=  \begin{bmatrix}
                              2c^2 & 0 \\
                              0    & 2
                            \end{bmatrix}
\end{aligncustom}

\noindent
This matrix has eigenvalues $2c ^ 2$ and $2$.  Since $c \ne 0$ by definition, this matrix is positive definition for all valid values of $c$.

\begin{subproblem}
  Program the steepest descent method (using your program from Problem~\ref{prob:ProgAlg} to find the step length).
\end{subproblem}

\begin{subproblem}
  Use your program to numerically solve this problem under two cases: i) $c=1$, ii) $c=10$.  Compare the convergence in these two cases.
\end{subproblem}

\begin{subproblem}
  Using Theorem 3.4, explain why as $c$ increases the convergence of the steepest descent method deteriorates.
\end{subproblem}

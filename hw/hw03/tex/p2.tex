\begin{problem}\label{prob:02}
  Code Algorithm~4.1 in Nocedal and Wrihght with:
  
  \begin{enumerate}
    \item Cauchy point method for the subproblem
    \item Dog-leg method based on the results for Exercise~\ref{prob:01}.
  \end{enumerate}

  \noindent
  Test and compare the performance of the methods on the following problem:
  
  \[\min_{x\in \mathbb{R}^n} f(x) = \log\left(1+x\transpose Qx\right)\]
  
  \noindent
  where $Q$ is symmetric and positive definite matrix.
\end{problem}


The gradient,~$g$, of $f$ is defined as: 

\[g = f'(x) = \frac{2Qx}{1+x\transpose Q x}\text{.}\]

\noindent
Table~\ref{tab:p02:experimentParameters} defines the parameters used in the experiments.  Note that $\mathcal{U}(a,b)$ represents a uniform random variable selected from the range $[a,b)$. Since $Q$ is positive, definite, then for all $x \ne [0]^n \implies x\transpose Q x > 0$.  Therefore, since $\log$ is a monotonically increasing function, $f$ is minimized when $\xopt = [0]^n$.

\begin{table}[h]
  \caption{Parameters used in the experiments for Exercise~\#\ref{prob:02}}\label{tab:p02:experimentParameters}
  \centering
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Name} & \textbf{Value} \\\hline
    \hline
    $\log$    &   Base 10\\\hline
    $n$       &   100\\\hline
    $\lambda$ &   $\mathcal{U}(10,1000)$ \\\hline
    $x_0$     &   Random vector from $\{[0,1)\}^{n}$\\\hline
    $\xopt$   &   $[0]^n$\\\hline
  \end{tabular}
\end{table}



